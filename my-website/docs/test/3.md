# Omitted Variable Bias

## The Simple Case

Imagine that the true population model has two independent variables and an error term:
$$
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + u,
$$
and we perform a simple regression of $y$ on $x_1$ only, obtaining the equation:
$$
\tilde{y} = \tilde{\beta_0} + \tilde{\beta_1} x_1.
$$
Because $x_2$ is not observed, we instead estimated the model:
$$
y = \beta_0 + \beta_1 x_1 + v,
$$
where $v=\beta_2 x_2+u$.

We know that $\tilde{\beta_1}=\hat{\beta_1} + \hat{\beta_2}\tilde{\delta_1}$ [[How]](https://macropy.com/Notebooks_Courses/).

The relationship between $\tilde{\beta_1}$ and $\hat{\beta_2}$ shows there are two distinct cases where they are equal:
1. The partial effect of $x_2$ on $\hat{y}$ is zero in the sample. That is, $\hat{\beta_2}=0$. 
2. $x_1$ and $x_2$ are uncorrelated in the sample. That is, $\tilde{\delta_1}=0$.

As $x_2$ is not observed, we don't have data on $x_2$. Therefore we will use expectation.

Again consider $\tilde{\beta_1}=\hat{\beta_1} + \hat{\beta_2}\tilde{\delta_1}$:
$$
\begin{align*}
\mathbb{E}[\tilde{\beta_1}]&=\mathbb{E}[\hat{\beta_1} + \hat{\beta_2}\tilde{\delta_1}] =\mathbb{E}[\hat{\beta_1}] + \mathbb{E}[\hat{\beta_2}]\tilde{\delta_1}\\
&=\beta_1 + \beta_2 \tilde{\delta_1}\\
Bias[\tilde{\beta_1}]&=\beta_2 \tilde{\delta_1}
\end{align*}
$$

<div style={{ textAlign: 'center' }}>
|                 | Corr($x_1, x_2$) > 0 | Corr($x_1, x_2$) < 0 |
|-----------------|----------------------|----------------------|
| $\beta_2$ â‰¥ 0   | Positive bias        | Negative bias        |
| $\beta_2$ < 0   | Negative bias        | Positive bias        |
</div>

**Terminologies:**

* **Upward Bias:** If $\mathbb{E}[\tilde{\beta_1}]>\beta_1$ then we say that $\tilde{\beta_1}$ has an upward bias.
* **Downward Bias:** If $\mathbb{E}[\tilde{\beta_1}]<\beta_1$ then we say that $\tilde{\beta_1}$ has a downward bias.
* **Biased towards zero:** The phrase *biased toward zero* refers to cases where $\mathbb{E}[\tilde{\beta_1}]$ is closer to zero than $\beta_1$ is. Therefore if $\beta_1$ is positive, then $\tilde{\beta_1}$ is biased toward zero if it has a downward bias. On the other hand, if $\beta_1$ is negative then $\tilde{\beta_1}$ is biased toward zero if it has an upward bias.

## The General Case

Hi

## Aside

$$
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + u\\
\mathbb{E}[y|x_1] = \beta_0 + \beta_1 x_1 + \beta_2 \mathbb{E}[x_2|x_1]\\
x_2 = \delta_0 + \delta_1 x_1 + c\\
\mathbb{E}[x_2|x_1] = \delta_0 + \delta_1 x_1\\
\mathbb{E}[y|x_1] = \beta_0 + \beta_1 x_1 + \beta_2 (\delta_0 + \delta_1 x_1)\\
\mathbb{E}[y|x_1] = \beta_0 + \beta_2 \delta_0+ (\beta_1 +\beta_2\delta_1) x_1\\
\tilde{\mathbb{E}}[y|x_1] = \tilde{\beta_0} + \tilde{\beta_1} x_1\\
$$