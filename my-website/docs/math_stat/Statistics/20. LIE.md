---
sidebar_position: 10
---
# Law of Iterated Expectations

## Discrete case

Under discrete case, Expectation is defined as follows
$$
\mathbb{E}[X]=x_1p_1+x_2p_2+...+x_np_n=\sum_{i=1}^n x_ip_i,
$$
can also be written as
$$
\mathbb{E}[X]=\sum_{i=1}^n (X=x_i)P(X=x_i),
$$
where random variable $X$ can take values $\{x_1,x_2,...,x_n\}$ with probabilities $\{p_1,p_2,...,p_n\}$ respectively.  

The **Law of Iterated Expectations** (LIE) states that:
$$
\mathbb{E}[X]=\mathbb{E}[\mathbb{E}[X|Y]]
$$
that is,  the expected value of the conditional expected value of $X$ given $Y$ is the same as the expected value of $X$.

**Proof:**

$$
\begin{align*}
    \mathbb{E}[\mathbb{E}[X|Y]]&=\sum_{y_i}\mathbb{E}[X|Y=y_i]P(Y=y_i)\\
    &=\sum_{y_i}\sum_{x_i}x_iP(X=x_i|Y=y_i)P(Y=y_i)
\end{align*}
$$
according to the Bayes' theorem
$$
\begin{align*}
  P(X=x_i|Y=y_i)&=\frac{P(X=x_i\text{ and }Y=y_i)}{P(Y=y_i)}, \text{ and}\\
  P(Y=y_i|X=x_i)&=\frac{P(X=x_i\text{ and }Y=y_i)}{P(X=x_i)}.\\
  \implies P(X=x_i|Y=y_i) P(Y=y_i)&=P(Y=y_i|X=x_i)P(X=x_i).
\end{align*}
$$
Therefore
$$
\begin{align*}
    \mathbb{E}[\mathbb{E}[X|Y]]&=\sum_{y_i}\sum_{x_i}x_iP(X=x_i|Y=y_i)P(Y=y_i)\\
    &=\sum_{y_i}\sum_{x_i}x_iP(Y=y_i|X=x_i)P(X=x_i)\\
    &=\sum_{y_i}\sum_{x_i}x_iP(X=x_i)P(Y=y_i|X=x_i)\\
    &=\sum_{x_i}x_iP(X=x_i)\underbrace{\sum_{y_i}P(Y=y_i|X=x_i)}_{=1}\\
    &=\sum_{x_i}x_iP(X=x_i)\\
    &=\mathbb{E}[X] \hspace{15px}\blacksquare
\end{align*}
$$