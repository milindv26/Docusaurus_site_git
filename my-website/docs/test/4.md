# Deriving the OLS Estimates

Here we will derive OLS estimates for both simple and multiple linear regression. 

## Simple linear regression

Our objective is to estimate the following model:
$$
y=\beta_0 + \beta_1x + u
$$
Since there are two unknowns $(\beta_0$ and $\beta_1)$, we need two equations. And we will use the following two equations (conditions):
* $\mathbb{E}[U]=0$, and
* $\mathbb{E}[U|X]=Cov(X,U)=\mathbb{E}[XU]=0$

Above conditions can be written as:
$$
\begin{align*}
    \mathbb{E}[y-\beta_0 - \beta_1x] &=0,\\
    \mathbb{E}[x(y-\beta_0 - \beta_1x)] &=0
\end{align*}
$$
Taking sample counterparts of the above equation:
$$
\begin{align*}
    n^{-1}\sum_{i=1}^n(y_i-\hat{\beta_0} - \hat{\beta_1}x_i) &=0,\tag{1}\\
    n^{-1}\sum_{i=1}^nx_i(y_i-\hat{\beta_0} - \hat{\beta_1}x_i) &=0 \tag{2}
\end{align*}
$$
Solving $(1)$, we get
$$
\begin{align*}
    \bar{y}&=\hat{\beta_0} + \hat{\beta_1}\bar{x}\\
    \implies \hat{\beta_0} &=\bar{y} - \hat{\beta_1}\bar{x} \tag{3}
\end{align*}
$$
where $\bar{y}$ and $\bar{x}$ are sample means of $y$ and $x$.

Substituting $(3)$ in $(2)$, we get
$$
\begin{align*}
    n^{-1}\sum_{i=1}^nx_i(y_i-\bar{y} + \hat{\beta_1}\bar{x} - \hat{\beta_1}x_i) &=0
\end{align*}
$$
$n^{-1}$ will go away because R.H.S is zero. Rearranging the above equation:
$$
\begin{align*}
    \sum_{i=1}^nx_i(y_i-\bar{y}) - \sum_{i=1}^nx_i\hat{\beta_1}(x_i-\bar{x}) &=0\\
    \sum_{i=1}^nx_i(y_i-\bar{y})&=\hat{\beta_1}\sum_{i=1}^nx_i(x_i-\bar{x}). \tag{4}
\end{align*}
$$
We know that:
$$
\begin{align*}
    \sum_{i=1}^nx_i(x_i-\bar{x})=\sum_{i=1}^n(x_i-\bar{x})^2\text{ and }\sum_{i=1}^nx_i(y_i-\bar{y})=\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y}).
\end{align*}
$$
[[How?]](ss)

Using the above equalities in $(1)$, we get:
$$
\hat{\beta_1}=\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^n(x_i-\bar{x})^2}.
$$
We can also find $\hat{\beta_0}$ by substitution $\hat{\beta_1}$ in $(3)$